---
title: "Predicting tornado numbers on convective days in the United States"
author: "Zoe Schroder"
date: "1/4/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

Code for publication in the Journal of Weather and Forecasting. 

*Load the package libraries needed for this research: *
```{r}
suppressMessages(library(dplyr))
suppressMessages(library(sf))
#devtools::install_github("ropensci/USAboundariesData")
suppressMessages(library(USAboundariesData))
suppressMessages(library(USAboundaries))
suppressMessages(library(tmap))
suppressMessages(library(ggplot2))
suppressMessages(library(lme4))
#devtools::install_github("paul-buerkner/brms")
suppressMessages(library(brms))
#devtools::install_github("rmcelreath/rethinking")
suppressMessages(library(rethinking)) 
suppressMessages(library(tidybayes))
#devtools::install_github("mvuorre/brmstools")
suppressMessages(library(brmstools)) 
suppressMessages(library(bayesplot))
suppressMessages(library(ggpubr))
suppressMessages(library(hexbin))
suppressMessages(library(ggstance))
suppressMessages(library(modelr))
suppressMessages(library(xtable))
suppressMessages(library(sp))
suppressMessages(library(lubridate))
suppressMessages(library(zoo))
```

*I load the data. The data file (BigDays.RData) comes from the DefineBigDays repository on github. (https://github.com/zschroder/DefineBigDays). I copy the BigDays.RData file from the DefineBigDays repository and add it to this project. This can be updated yearly by adding the latest tornado csv file from the Storm Prediction Center. Additionally, we can define an outbreak as an arbitrary number of tornadoes. *
```{r}
load("BigDays.RData")

BigDays.sfdfT <- BigDays.sfdfT %>%
  mutate(TorPerHour = nT/as.numeric(Duration) * 3600,
         TorPerKm = nT/as.numeric(HullArea) * 10^6)
dim(BigDays.sfdfT)
```

##################
## Introduction ##
##################

Predicting specific characteristics of severe weather outbreaks is an important but challenging problem. Guidance from numerical models helps forecasters outline areas of severe weather threats days in advance. For example, ... Guidance from statistical models helps forecasters quantify probabilities for given severe weather events \citep{HitchensandBrooks2014, ThompsonEtAl2017, Cohen2018, ElsnerSchroder2019}. For example, \cite{Cohen2018} develop a regression model to specify the probability of tornado occurrence given certain environmental and storm-scale conditions. And \cite{ElsnerSchroder2019} extend this model by making use of the cumulative logistic link function that predicts probabilities by for each damage rating.

These latter studies put statistical guidance for predicting tornado outbreak characteristics on a firm mathematical foundation, yet there is room for additional work. For instance, the cumulative logistic regression provides a distribution for the {\it percentage} of tornadoes within each Enhanced Fujita (EF) rating category, but the regression model is silent concerning the overall number of tornadoes. Here we propose a method to model the expected overall number of tornadoes given environmental conditions. The model allows us to quantify the interrelationships between environmental variables and tornado frequency. It also helps in extending the available statistical guidance because output from the proposed model together with output from the cumulative logistic model provides a prediction for the expected number of tornadoes by each EF category. Suppose for example that given current environmental conditions the proposed model predicts a distribution for the total number of tornadoes centered on fifteen while the cumulative logistic regression model predicts that for each tornado there is a fifty percent change of it being EF0, a ten percent chance of it being EF1, a five percent change of it being EF2, and so on. Then a numerical convolution of these two distributions provides an expected number of counts by EF rating as well as the associated uncertainties.

This paper has two goals: (1) demonstrate a statistical methodology for estimating the number of tornadoes given well-known environmental conditions and (2) improve the understanding of the role these environmental conditions have on tornado 'outbreaks'. We accomplish these goals by fitting a truncated Poisson regression model to tornado counts on 'big' convective days (12 UTC to 12 UTC), where the number of tornadoes is at least ten. Thus in demonstrating the approach, we condition our model on the occurrence of a tornado `outbreak' (at least ten tornadoes) as was done in \cite{ElsnerSchroder2019}. Towards improving our understanding of the role environmental conditions play on the number tornadoes in an outbreak, we allow for interactions among the variables. We find ... The paper is outlined as follows. The data used to demonstrate the model are described in section 2.  The mathematics of a truncated Poisson regression are given in section 3. Model results are presented in section 4, and a summary and a list of the main conclusions are given in section 5.

##########
## Data ##
##########

We advance our goals by fitting statistical models to a set of observed data aggregated to the level of tornado clusters. Here we describe the available data and the procedures we use to aggregate the values to the cluster level. For our purposes, a cluster is a spatial group of at least ten tornadoes occurring between 12 UTC and 12 UTC. Ten is chosen as a compromise between too few clusters leading to greater uncertainty and too many clusters leading to excessive time required to fit the models \citep{ElsnerSchroder2019}. Cluster size, defined as the number of tornadoes, serves as the response variable in the statistical models. Explanatory variables for the models are extracted from reanalysis data representing the environment prior to the occurrence of the first tornado in the cluster.

## Tornado clusters ##


First, we extract the date, time, genesis location, and magnitude for all tornadoes between 1994 and 2018 in the record obtained from the Storm Prediction Center [SPC] (\url{https://www.spc.noaa.gov/gis/svrgis/}). We choose 1994 as the start year because it is the first year of the extensive use of the WSR-88D Radar.  Each row in the data set contains information at the individual tornado level. In total, there are 30~497 tornado records during this period. The geographic coordinates for each genesis location are converted to Lambert conic conformal coordinates, where the projection is centered on 107$^{\circ}$~W longitude. 

*Compute the total number of tornadoes between 1994 and 2018.*
```{r}
US_LCC <- "+proj=lcc +lat_1=33 +lat_2=45 +lat_0=39 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m no_defs"

#sp::coordinates(All_Tornadoes) <- ~ elon + elat
#Torn50_19.sfdf <- st_as_sf(Torn50_19.spdf)
#st_crs(Torn50_19.sfdf) <- WGS84

#st_crs(All_Tornadoes) <- WGS84
#  spgeo <- st_transform(All_Tornadoes, CRS("+proj=longlat +datum=WGS84"))

#All_Tornadoes <- st_transform(All_Tornadoes, crs = st_crs(US_LCC))
Backup<- All_Tornadoes
dim(All_Tornadoes)[1]
#30,497
```

Next, we assign to each tornado a cluster identification (ID) based on the space and time differences between genesis locations. Two tornadoes are assigned the same cluster ID if they occur close together in space and time (e.g., 1~km and 1~h).  When the difference between individual tornadoes and existing clusters surpasses 50~000~s ($\sim$ 14~h), the clustering ends. The space-time differences have units of seconds because we divide the spatial distance by 15~m~s$^{-1}$ to account for the average speed of tornado-producing storms. This clustering of tornadoes is identical to that used in \cite{ElsnerSchroder2019} to fit the cumulative logistic model to the damage scale. Additional details on the procedure as well as a comparison of the identified clusters to well-known tornado outbreaks are available in \cite{SchroderElsner2019}.

We keep only clusters that have at least ten tornadoes occurring within the same convective day, which results in 768 clusters containing a total of 17~069 tornadoes. A convective day is defined as a 24-hour period beginning at 1200 UTC \citep{DoswellEtAl2006}. Cluster size is defined here as the number of tornadoes in the cluster ($N$). The average cluster size (for clusters with at least ten tornadoes) is 22 tornadoes and the maximum is 173 tornadoes (April 27, 2011). There are 80 clusters with a size of exactly ten tornadoes. Each cluster varies by area and by where it occurs (Fig.~\ref{fig:Clusters}). The cluster area is defined by the minimum convex hull (black polygon) that includes all the tornado genesis locations. The July 19, 1994 cluster with nine tornadoes over northern Iowa and one over northeast Wisconsin had an area of 33~359 sq. km. The April 27, 2011 cluster had 173 tornadoes spread over more than a dozen states had an area of 1~064~337 sq. km. 

*How many tornadoes between 1994 and 2018 occurred in clusters of ten or more?*
```{r}
dim(BigDayTornadoes)[1]
#17,069
```

*Compute summary statistics (mean, median, mode,etc) for the clusters*
```{r}
min(BigDays.sfdfT$nT)
#10

max(BigDays.sfdfT$nT)
#173

median(BigDays.sfdfT$nT)
#17

mean(BigDays.sfdfT$nT)
#22.22526
```

*How many have a nT = 10?*
```{r}
sum(BigDays.sfdfT$nT == 10)
#80
```

*Create a figure of 4 clusters in the data set.* 
`Generate the state and county borders`
```{r}
sts <- state.name[!state.name %in% c("Alaska", "Hawaii")]
stateBorders <- us_states(states = sts)
counties.sf <- us_counties()
```

`Generate a color ramp that you like`
```{r}
cr <- RColorBrewer::brewer.pal(9, "Greys")
cr <- cr[-c(1:3)]
```

`Create the unique ID for the All_Tornadoes file`
```{r}
All_Tornadoes<- All_Tornadoes %>%
   mutate(ID = paste0(gsub("-", "", cDate), groupNumber))
```

```{r}
BigDays.sfdfT <- BigDays.sfdfT %>%
  mutate(A = as.numeric(HullArea)/10^10,
         CAPE = maxCAPE/1000,
         CIN = minCIN/100,
         DLBS = maxBS_deep/10,
         SLBS = maxBS_shallow/10)
dim(BigDays.sfdfT)
```

```{r}
merc <- "+proj=merc +lon_0=0 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
```
`Extract the smallest day and associated tornadoes. Get summary statistics of the big day`
```{r}
#Extract the big day using the unique ID created.
cluster1 <- BigDays.sfdfT %>%
  filter(ID == 19940719217)

#Generate a convex hull around the cluster.
cluster1 <- st_convex_hull(cluster1)

#Extract all tornadoes that are in the Day 1
cluster1torns <- All_Tornadoes %>%
  filter(ID == 19940719217)

cluster1torns$mag <- as.numeric(cluster1torns$mag)
cluster1torns$mag2 <- cut(cluster1torns$mag, breaks=c(-1, 0, 1, 2, 3, 4, 5))
```

```{r}
A <- tm_shape(stateBorders) + 
  tm_borders(col = "gray70") +
tm_shape(cluster1) + 
  tm_borders(col = "gray15", 
             alpha = 1, 
             lwd = 2) +
  tm_scale_bar(color.dark = "gray70", 
               width = .3, 
               size = 1, 
               lwd = 2, 
               position = c("left","bottom")) +
    tm_compass(color.dark = "gray70", 
             size = 5, 
             lwd = 2, 
             position = c("left","top")) + 
    tm_format("World", 
              attr.position = c("left", "top"),
              legend.frame = FALSE,
              inner.margins = c(.25, .2, .2, .2)) +
    tm_layout(legend.bg.color = "white", 
            legend.text.size = .75) + 
  tm_shape(cluster1torns, 
         projection = merc, 
         is.master = TRUE) +
    tm_symbols(size = 3, 
               col = "mag2", 
               n = 6, 
               palette = cr, 
               alpha = 0.8, 
               border.alpha = 0, 
               labels = c("0", "1", "2", "3", "4", "5"), 
               title.col = "EF Rating") +
    tm_layout(title = "July 19, 1994 \n 10 tornadoes", 
              title.position = c("center", "top"), 
              legend.title.size = 1.4,
              legend.position = c("right", "bottom"), 
              legend.stack = "horizontal",
              legend.frame = FALSE, 
              legend.text.size = 1.2, 
              legend.width = -0.2, 
              title.size = 1.5)
A  
```

```{r}
All_Tornadoes<- Backup %>%
   mutate(ID = paste0(gsub("-", "", cDate), groupNumber))
```


```{r}
cluster2 <- BigDays.sfdfT %>%
  filter(ID == 199906061644)

cluster2 <- st_convex_hull(cluster2)

cluster2torns <- All_Tornadoes %>%
  filter(ID == 199906061644) 

cluster2 %>%
  summarize(Area = HullArea/(10**6),
            Duration = Duration/3600)

cluster2torns$mag <- as.numeric(cluster2torns$mag)
cluster2torns$mag2 <- cut(cluster2torns$mag, breaks=c(-1, 0, 1, 2, 3, 4, 5))

#st_transform(cluster2torns, crs = merc)
```

```{r}
B <- tm_shape(stateBorders) + 
  tm_borders(col = "gray70") +
tm_shape(cluster2) + 
  tm_borders(col = "gray15", 
             alpha = 1, 
             lwd = 2) +
  tm_scale_bar(color.dark = "gray70", 
               width = .2, 
               size = 1, 
               lwd = 2, 
               position = c("left","bottom")) +
    tm_compass(color.dark = "gray70", 
             size = 5, 
             lwd = 2, 
             position = c("left","top")) + 
    tm_format("World", 
              attr.position = c("left", "top"),
              legend.frame = FALSE,
              inner.margins = c(.1, .1, .1, .1)) +
    tm_layout(legend.bg.color = "white", 
            legend.text.size = .75) + 
  tm_shape(cluster2torns, 
         projection = merc, 
         is.master = TRUE) +
    tm_symbols(size = 3, 
               col = "mag2", 
               n = 6, 
               palette = cr, 
               alpha = 0.8, 
               border.alpha = 0, 
               labels = c("0", "1", "2", "3", "4", "5"), 
               title.col = "EF Rating") +
    tm_layout(title = "June 6, 1999 \n 36 tornadoes", 
              title.position = c("center", "top"), 
              legend.title.size = 1.4,
              legend.position = c("right", "bottom"), 
              legend.stack = "horizontal",
              legend.frame = FALSE, 
              legend.text.size = 1.2, 
              legend.width = -0.15, 
              title.size = 1.5)
  B
```

Separate June 6, 1999 into multiple clusters. 
```{r}
cluster2 <- BigDays.sfdfT %>%
  filter(ID == 199906061644)

cluster2 <- st_convex_hull(cluster2)

cluster2torns <- All_Tornadoes %>%
  filter(ID == 199906061644, elat >= 46) 

cluster2 %>%
  summarize(Area = HullArea/(10**6),
            Duration = Duration/3600)

cluster2torns$mag <- as.numeric(cluster2torns$mag)
cluster2torns$mag2 <- cut(cluster2torns$mag, breaks=c(-1, 0, 1, 2, 3, 4, 5))


Group_23 <- All_Tornadoes %>%
  filter(ID == 199906061644, elat >= 46) %>%
  group_by(groupNumber, cDate) %>%
  summarize(nT = n(),
            n0 = sum(mag == 0),
            n1 = sum(mag == 1),
            n2 = sum(mag == 2),
            n3 = sum(mag == 3),
            n4 = sum(mag == 4),
            n5 = sum(mag == 5),
            ATP = sum(ED),
            maxATP = max(ED),
            avgATP = mean(ED),
            GroupDayCas = sum(cas),
            GroupDayFat = sum(fat),
            StartTime_CST = first(DateTime),
            EndTime_CST= last(DateTime),
            StartTime_UTC = StartTime_CST + 21600,
            EndTime_UTC = EndTime_CST + 21600,
            Duration = difftime(EndTime_CST, StartTime_CST, units = "secs")) #%>%
  #filter(nT >= 10) %>%

 # mutate(Year = year(cDate),
  #       Mo = month(cDate),
   #      Month = format(cDate, "%m"), # this is needed to preserve the leading zeros
    #     Day = format(cDate, "%d"), 
    #     ATP_TW = ATP/10^12) 
```

```{r}
Group_23 <- st_convex_hull(Group_23)

G1<- #tm_shape(stateBorders) + 
  #tm_borders(col = "gray70") +
tm_shape(Group_23) + 
  tm_borders(col = "gray15", 
             alpha = 1, 
             lwd = 2) +
  tm_scale_bar(color.dark = "gray70", 
               width = .2, 
               size = 1, 
               lwd = 2, 
               position = c("left","bottom")) +
    tm_compass(color.dark = "gray70", 
             size = 5, 
             lwd = 2, 
             position = c("left","top")) + 
    tm_format("World", 
              attr.position = c("left", "top"),
              legend.frame = FALSE,
              inner.margins = c(.2, .1, .2, .1)) +
    tm_layout(legend.bg.color = "white", 
            legend.text.size = .75) + 
  tm_shape(cluster2torns, 
         projection = "+proj=merc +lon_0=0 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs", 
         is.master = TRUE) +
    tm_symbols(size = 3, 
               col = "mag2", 
               n = 6, 
               palette = cr, 
               alpha = 0.8, 
               border.alpha = 0, 
               labels = c("0", "1", "2", "3", "4", "5"), 
               title.col = "EF Rating") +
    tm_layout(title = "June 6, 1999 \n 23 tornadoes", 
              title.position = c("center", "top"), 
              legend.title.size = 1.4,
              legend.position = c("right", "bottom"), 
              legend.stack = "horizontal",
              legend.frame = FALSE, 
              legend.text.size = 1.2, 
              legend.width = -0.15, 
              title.size = 1.5)
G1
```

Get the centroid (central point of the tornado activity) for each big day. 
```{r, eval = FALSE}
Group_23Centroids.df <- st_centroid(Group_23)
Group_23Centroids.df$groupArea <- st_area(st_convex_hull(Group_23))
Group_23Centroids.df$groupDensity <- Group_23Centroids.df$nT/Group_23Centroids.df$groupArea
```

```{r}
library(xts)
Group_23$StartTime_UTC <- force_tz(Group_23$StartTime_UTC, tzone = "UTC")
Group_23$NARRtime <- (align.time(Group_23$StartTime_UTC, n = (60 * 60 * 3)) - 3600 * 3)
```

Split the NARR date and time into their individual variables. Then bind the columns for BigDays.sfdfT. NOTE: cannot do a mutate because 00Z produces NAs. DON'T USE!
```{r, eval = FALSE}
NARRday = format(as.POSIXct(strptime(Group_23$NARRtime,"%Y-%m-%d %H:%M:%S",tz="")) ,format = "%Y/%m/%d")
NARRZtime = format(as.POSIXct(strptime(Group_23$NARRtime,"%Y-%m-%d %H:%M:%S",tz="")) ,format = "%H")
Group_23 <- cbind(Group_23, NARRday, NARRZtime)
```

Create a downloadable string of information for the varying NARR times. 
```{r, eval = FALSE}
Group_23 <- Group_23 %>%
  mutate(YrMoDa = gsub("/", "", NARRday),
         slug = paste0("merged_AWIP32.",YrMoDa, NARRZtime),
         slug2 = paste0("merged_AWIP32.",YrMoDa))
```

```{r}
library(raster)
```


```{r}
avgCAPE <- numeric()
avgsbCAPE <- numeric()
avgDEW <- numeric()
avgMR <- numeric()
avgHLCY <- numeric()
avgCIN <- numeric()
avgsbCIN <- numeric()
avgUSTM <- numeric()
avgVSTM <- numeric()
avgBS_deep <- numeric()
avgBS_shallow <- numeric()
avgSM <- numeric()
avgRATIO <- numeric()
avgLCL <- numeric()
maxCAPE <- numeric()
maxsbCAPE <- numeric()
maxDEW <- numeric()
maxMR <- numeric()
maxHLCY <- numeric()
minCIN <- numeric()
minsbCIN <- numeric()
maxUSTM <- numeric()
maxVSTM <- numeric()
maxBS_deep <- numeric()
maxBS_shallow <- numeric()
maxSM <- numeric()
maxLCL <- numeric()
minLCL <- numeric()
 
for(i in 1){
  print(i)
  rb <- brick(paste0("/Users/zoeschroder/Desktop/Projects/Torn_Freq/", Group_23$slug2[i], "/", Group_23$slug[i]))
 # rb <- brick(paste0("/Users/lordofmornin/Desktop/Projects/Torn_Freq/", Group_23$slug2[i], "/", Group_23$slug[i])) #<-- this is for varying NARR times
  CAPE <- raster(rb, layer = 375)
  sbCAPE <- raster(rb, layer = 315)
  DEW <- raster(rb, layer = 290)
  MR <- raster(rb, layer = 289)
  HLCY <- raster(rb, layer = 323)
  CIN <- raster(rb, layer = 376)
  sbCIN <- raster(rb, layer = 316)
  USTM <- raster(rb, layer = 324)
  VSTM <- raster(rb, layer = 325)
  UGRD500 <- raster(rb, layer = 117) 
  VGRD500 <- raster(rb, layer = 118) 
  UGRD850 <- raster(rb, layer = 206) 
  VGRD850 <- raster(rb, layer = 207)
  UGRDsfc <- raster(rb, layer = 293) 
  VGRDsfc <- raster(rb, layer = 294)  
  LCL <- raster(rb, layer = 319)
  SM <- sqrt(USTM^2 + VSTM^2)
  RATIO <- CAPE/abs(CIN)
  BS_deep <- sqrt(((UGRD500 - UGRDsfc)**2) + ((VGRD500 - VGRDsfc)**2))
  BS_shallow <- sqrt(((UGRD850 - UGRDsfc)**2) + ((VGRD850 - VGRDsfc)**2))
  avgCAPE <- c(avgCAPE, as.numeric(raster::extract(CAPE, Group_23[i, ], fun = mean)))
  avgsbCAPE <- c(avgsbCAPE, as.numeric(raster::extract(sbCAPE, Group_23[i, ], fun = mean)))
  maxCAPE <- c(maxCAPE, as.numeric(raster::extract(CAPE, Group_23[i, ], fun = max)))
  maxsbCAPE <- c(maxsbCAPE, as.numeric(raster::extract(sbCAPE, Group_23[i, ], fun = max)))
  avgDEW <- c(avgDEW, as.numeric(raster::extract(DEW, Group_23[i, ], fun = mean)))
  maxDEW <- c(maxDEW, as.numeric(raster::extract(DEW, Group_23[i, ], fun = max)))
  avgMR <- c(avgMR, as.numeric(raster::extract(MR, Group_23[i, ], fun = mean)))
  maxMR <- c(maxMR, as.numeric(raster::extract(MR, Group_23[i, ], fun = max)))
  avgHLCY <- c(avgHLCY, as.numeric(raster::extract(HLCY, Group_23[i, ], fun = mean)))
  maxHLCY <- c(maxHLCY, as.numeric(raster::extract(HLCY, Group_23[i, ], fun = max)))
  avgCIN <- c(avgCIN, as.numeric(raster::extract(CIN, Group_23[i, ], fun = mean)))
  avgsbCIN <- c(avgsbCIN, as.numeric(raster::extract(sbCIN, Group_23[i, ], fun = mean)))
  minCIN <- c(minCIN, as.numeric(raster::extract(CIN, Group_23[i, ], fun = min)))
  minsbCIN <- c(minsbCIN, as.numeric(raster::extract(sbCIN, Group_23[i, ], fun = min)))
  avgUSTM <- c(avgUSTM, as.numeric(raster::extract(USTM, Group_23[i, ], fun = mean)))
  maxUSTM <- c(maxUSTM, as.numeric(raster::extract(USTM, Group_23[i, ], fun = max)))
  avgVSTM <- c(avgVSTM, as.numeric(raster::extract(VSTM, Group_23[i, ], fun = mean)))
  maxVSTM <- c(maxVSTM, as.numeric(raster::extract(VSTM, Group_23[i, ], fun = max)))
  avgSM <- c(avgSM, as.numeric(raster::extract(SM, Group_23[i, ], fun = mean)))
  maxSM <- c(maxSM, as.numeric(raster::extract(SM, Group_23[i, ], fun = max)))
  avgRATIO <- c(avgRATIO, as.numeric(raster::extract(RATIO, Group_23[i, ], fun = mean)))
  avgBS_deep <- c(avgBS_deep, as.numeric(raster::extract(BS_deep, Group_23[i, ], fun = mean)))
  maxBS_deep <- c(maxBS_deep, as.numeric(raster::extract(BS_deep, Group_23[i, ], fun = max)))  
  avgBS_shallow <- c(avgBS_shallow, as.numeric(raster::extract(BS_shallow, Group_23[i, ], fun = mean)))
  maxBS_shallow <- c(maxBS_shallow, as.numeric(raster::extract(BS_shallow, Group_23[i, ], fun = max)))
  avgLCL <- c(avgLCL, as.numeric(raster::extract(LCL, Group_23[i,], fun = mean)))
  maxLCL <- c(maxLCL, as.numeric(raster::extract(LCL, Group_23[i,], fun = max)))
  minLCL <- c(minLCL, as.numeric(raster::extract(LCL, Group_23[i,], fun = min)))
}
```

Add environmental data values to the group day means data frame.
```{r}
Group_23$avgCAPE <- avgCAPE
Group_23$avgsbCAPE <- avgsbCAPE
Group_23$maxCAPE <- maxCAPE
Group_23$maxsbCAPE <- maxsbCAPE
Group_23$avgDEW <- avgDEW
Group_23$maxDEW <- maxDEW
Group_23$avgMR <- avgMR
Group_23$maxMR <- maxMR
Group_23$avgHLCY <- avgHLCY
Group_23$maxHLCY <- maxHLCY
Group_23$avgCIN <- avgCIN
Group_23$avgsbCIN <- avgsbCIN
Group_23$minCIN <- minCIN
Group_23$minsbCIN <- minsbCIN
Group_23$avgUSTM <- avgUSTM
Group_23$maxUSTM <- maxUSTM
Group_23$avgVSTM <- avgVSTM
Group_23$maxVSTM <- maxVSTM
Group_23$avgBS_deep <- avgBS_deep
Group_23$maxBS_deep <- maxBS_deep
Group_23$avgBS_shallow <- avgBS_shallow
Group_23$maxBS_shallow <- maxBS_shallow
Group_23$avgRATIO <- avgRATIO
Group_23$avgSM <- avgSM
Group_23$maxSM <- maxSM
Group_23$minLCL <- minLCL
Group_23$maxLCL <- maxLCL
Group_23$avgLCL <- avgLCL
```

```{r}
for(i in 1){
  print(i)
    rb <- brick(paste0("/Users/zoeschroder/Desktop/Projects/Torn_Freq/", Group_23$slug2[i], "/", Group_23$slug[i]))
  #rb <- brick(paste0("/Users/lordofmornin/Desktop/Projects/Torn_Freq/", Group_23$slug2[i], "/", Group_23$slug[i]))
  CAPE <- raster(rb, layer = 375)
  HLCY <- raster(rb, layer = 323)
  CIN <- raster(rb, layer = 376)
  UGRD500 <- raster(rb, layer = 117) 
  VGRD500 <- raster(rb, layer = 118) 
  UGRDsfc <- raster(rb, layer = 293) 
  VGRDsfc <- raster(rb, layer = 294)     
  BS <- sqrt(((UGRD500 - UGRDsfc)**2) + ((VGRD500 - VGRDsfc)**2))
}
```


```{r}
BigDays.sfdfT <- BigDays.sfdfT %>%
 mutate(ID = paste0(gsub("-", "", cDate), groupNumber))
```
*May 6, 2003 Big Day*

```{r}
groupDayCentroids.sfdfT <- st_centroid(BigDays.sfdfT)
groupDayCentroids.sfdfT$groupArea <- st_area(st_convex_hull(BigDays.sfdfT))
groupDayCentroids.sfdfT$groupDensity <- groupDayCentroids.sfdfT$nT/groupDayCentroids.sfdfT$groupArea
```

```{r}
June6 <- BigDays.sfdfT %>%
  filter(ID == "199906061644")
June6 <- st_convex_hull(June6)
June6centroid <- groupDayCentroids.sfdfT %>%
  filter(ID == "199906061644")
June6tornadoes <- All_Tornadoes %>% 
  filter(ID == "199906061644")
```
*Plot the CAPE, HLCY, and CIN for the June 6, 2003 Big Day. First, read in the raster. *
```{r}
i=1
   rb <- brick(paste0("/Users/zoeschroder/Desktop/Projects/Torn_Freq/", Group_23$slug2[i], "/", Group_23$slug[i])) #rb <- brick(paste0("/Volumes/Zoe's Home/NCARNARR/All/", BigDays.sfdfT$slug2[i], "/",BigDays.sfdfT$slug[i])) #<-- this is for varying NARR times
  CAPE <- raster(rb, layer = 375)
  HLCY <- raster(rb, layer = 323)
  CIN <- raster(rb, layer = 376)
  UGRD500 <- raster(rb, layer = 117) 
  VGRD500 <- raster(rb, layer = 118) 
  UGRDsfc <- raster(rb, layer = 293) 
  VGRDsfc <- raster(rb, layer = 294)     
  BS <- sqrt(((UGRD500 - UGRDsfc)**2) + ((VGRD500 - VGRDsfc)**2))
```
**Convective Available Potential energy **
```{r}
CAPE_June6 <- crop(CAPE, extent(June6))
CAPE_extent<- mask(CAPE_June6, June6)
plot(CAPE_extent)
maxCAPE <- which.max(CAPE_extent) #Returns a pixel number
#Test that this max value equals the one in BigDays.sfdfT
test <- getValues(CAPE_extent) 
test<-as.matrix(test, ncol=1)
```

```{r}
CAPEmaxpos <- xyFromCell(CAPE_extent, maxCAPE)
xy <- data.frame(CAPEmaxpos)
CAPE_latlon <- data.frame(lon=xy$x, lat=xy$y)
print(CAPE_latlon)
CAPE_latlon <- SpatialPoints(CAPE_latlon)
proj4string(CAPE_latlon) = CRS("+proj=lcc +lat_1=50 +lat_2=50 +lat_0=50 +lon_0=-107 +x_0=0 +y_0=0 +a=6371200 +b=6371200 +units=m +no_defs")
```

```{r}
#install.packages("USAboundariesData")
counties <- us_counties()
states <- us_states()
```

```{r, eval = FALSE}
p1 <- tm_shape(CAPE_extent) +
  tm_raster(title = "",  n = 6, palette = "Greys") +
  tm_format(title = expression(paste("CAPE [J ", kg^-1, "]")), "World", legend.position = c("left", "bottom"),
                   attr.position = c("left", "bottom"),
                   legend.frame = FALSE,
                   inner.margins = c(.1, 0.18, .1, .18), #bottom, left, top
                    legend.text.size = 1, legend.width = -0.28, legend.title.size=1, legend.bg.color = "white", title.size = 1.4) +
#tm_shape(counties) +
  #tm_borders(col = "grey") +
  tm_scale_bar(width = 0.3, size = 0.8, position = c("right", "top"), color.dark = "gray70") +
tm_shape(states) +
  tm_borders() +
tm_shape(June6, is.master = TRUE, projection = merc) +
  tm_borders(col = "black", lwd = 3)  +
#tm_shape(June6tornadoes) +
#  tm_symbols(size = 1.25, col = "black", shape = 24) +
tm_shape(CAPE_latlon) + 
  tm_symbols(size = 1.4, col = "black", shape = 22) + 
    tm_shape(June6tornadoes, 
         projection = "+proj=merc +lon_0=0 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs", 
         is.master = TRUE) +
    tm_symbols(size = 3)
p1
```


```{r}
cluster2 <- BigDays.sfdfT %>%
  filter(ID == 199906061644)

#test<- st_crs(All_Tornadoes, "+proj=lcc +lat_1=50 +lat_2=50 +lat_0=50 +lon_0=-107 +x_0=0 +y_0=0 +a=6371200 +b=6371200 +units=m +no_defs")

All_Tornadoes <- st_transform(All_Tornadoes, 
  crs = "+proj=lcc +lat_1=50 +lat_2=50 +lat_0=50 +lon_0=-107 +x_0=0 +y_0=0 +a=6371200 +b=6371200 +units=m +no_defs")

G23torns <- All_Tornadoes %>%
  filter(ID == 199906061644, elat >= 46) 

G23torns$mag <- as.numeric(G23torns$mag)
G23torns$mag2 <- cut(G23torns$mag, breaks=c(-1, 0, 1, 2, 3, 4, 5))


G23 <- All_Tornadoes %>%
  filter(ID == 199906061644, elat >= 46) %>%
  group_by(groupNumber, cDate) %>%
  summarize(nT = n(),
            n0 = sum(mag == 0),
            n1 = sum(mag == 1),
            n2 = sum(mag == 2),
            n3 = sum(mag == 3),
            n4 = sum(mag == 4),
            n5 = sum(mag == 5),
            ATP = sum(ED),
            maxATP = max(ED),
            avgATP = mean(ED),
            GroupDayCas = sum(cas),
            GroupDayFat = sum(fat),
            StartTime_CST = first(DateTime),
            EndTime_CST= last(DateTime),
            StartTime_UTC = StartTime_CST + 21600,
            EndTime_UTC = EndTime_CST + 21600,
            Duration = difftime(EndTime_CST, StartTime_CST, units = "secs")) #%>%
  #filter(nT >= 10) %>%

 # mutate(Year = year(cDate),
  #       Mo = month(cDate),
   #      Month = format(cDate, "%m"), # this is needed to preserve the leading zeros
    #     Day = format(cDate, "%d"), 
    #     ATP_TW = ATP/10^12) 

G23 <- st_convex_hull(G23)

G23DayCentroids.sfdfT <- st_centroid(G23)
G23DayCentroids.sfdfT$groupArea <- st_area(st_convex_hull(G23))
#G23DayCentroids.sfdfT$groupDensity
```


**Convective Available Potential energy **
```{r}

CAPE_G23 <- crop(CAPE, extent(G23))
CAPE_extent<- mask(CAPE_G23, G23)
plot(CAPE_extent)
maxCAPE <- which.max(CAPE_extent) #Returns a pixel number
#Test that this max value equals the one in BigDays.sfdfT
test <- getValues(CAPE_extent) 
test<-as.matrix(test, ncol=1)
```

```{r}
CAPEmaxpos <- xyFromCell(CAPE_extent, maxCAPE)
xy <- data.frame(CAPEmaxpos)
CAPE_latlon <- data.frame(lon=xy$x, lat=xy$y)
print(CAPE_latlon)
CAPE_latlon <- SpatialPoints(CAPE_latlon)
proj4string(CAPE_latlon) = CRS("+proj=lcc +lat_1=50 +lat_2=50 +lat_0=50 +lon_0=-107 +x_0=0 +y_0=0 +a=6371200 +b=6371200 +units=m +no_defs")
```

```{r, eval = FALSE}
p1 <- tm_shape(CAPE_extent) +
  tm_raster(title = "",  n = 6, palette = "Greys") +
  tm_format(title = expression(paste("CAPE [J ", kg^-1, "]")), "World", legend.position = c("right", "bottom"),
                   attr.position = c("right", "bottom"),
                   legend.frame = FALSE,
                   inner.margins = c(.1, 0, .1, .18), #bottom, left, top
                    legend.text.size = 1, legend.width = -0.28, legend.title.size=1, legend.bg.color = "white", title.size = 1.4) +
#tm_shape(counties) +
  #tm_borders(col = "grey") +
  tm_scale_bar(width = 0.3, size = 0.8, position = c("right", "top"), color.dark = "gray70") +
tm_shape(stateBorders) +
  tm_borders() +
tm_shape(G23, is.master = TRUE, projection = merc) +
  tm_borders(col = "black", lwd = 3)  +
#tm_shape(June6tornadoes) +
#  tm_symbols(size = 1.25, col = "black", shape = 24) +
tm_shape(CAPE_latlon) + 
  tm_symbols(size = 1.4, col = "black", shape = 22) + 
    tm_shape(G23torns, 
         projection = "+proj=merc +lon_0=0 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs", 
         is.master = TRUE) +
    tm_symbols(size = 3)
p1
```




KEEP: 
```{r}
cluster2torns <- All_Tornadoes %>%
  filter(ID == 199906061644) 
Group1$HullArea <- st_area(Group1)
Group1Hull <- st_convex_hull(Group1)
Group1torns <- cluster2torns %>%
  filter(elat >= 46)
Group2torns <- cluster2torns %>%
  filter(elat < 46)
Group1 <- All_Tornadoes %>%
  filter(ID == 199906061644, elat >= 46) %>%
  group_by(groupNumber, cDate) %>%
  summarize(nT = n(),
            n0 = sum(mag == 0),
            n1 = sum(mag == 1),
            n2 = sum(mag == 2),
            n3 = sum(mag == 3),
            n4 = sum(mag == 4),
            n5 = sum(mag == 5),
            ATP = sum(ED),
            maxATP = max(ED),
            avgATP = mean(ED),
            GroupDayCas = sum(cas),
            GroupDayFat = sum(fat),
            StartTime_CST = first(DateTime),
            EndTime_CST= last(DateTime),
            StartTime_UTC = StartTime_CST + 21600,
            EndTime_UTC = EndTime_CST + 21600,
            Duration = difftime(EndTime_CST, StartTime_CST, units = "secs")) %>%
  filter(nT >= 10) %>%
  mutate(Year = year(cDate),
         Mo = month(cDate),
         Month = format(cDate, "%m"), # this is needed to preserve the leading zeros
         Day = format(cDate, "%d"), 
         ATP_TW = ATP/10^12) 

Group2 <- All_Tornadoes %>%
  filter(ID == 199906061644, elat < 46) %>%
  group_by(groupNumber, cDate) %>%
  summarize(nT = n(),
            n0 = sum(mag == 0),
            n1 = sum(mag == 1),
            n2 = sum(mag == 2),
            n3 = sum(mag == 3),
            n4 = sum(mag == 4),
            n5 = sum(mag == 5),
            ATP = sum(ED),
            maxATP = max(ED),
            avgATP = mean(ED),
            GroupDayCas = sum(cas),
            GroupDayFat = sum(fat),
            StartTime_CST = first(DateTime),
            EndTime_CST= last(DateTime),
            StartTime_UTC = StartTime_CST + 21600,
            EndTime_UTC = EndTime_CST + 21600,
            Duration = difftime(EndTime_CST, StartTime_CST, units = "secs")) %>%
  filter(nT >= 10) %>%
  mutate(Year = year(cDate),
         Mo = month(cDate),
         Month = format(cDate, "%m"), # this is needed to preserve the leading zeros
         Day = format(cDate, "%d"), 
         ATP_TW = ATP/10^12) 
Group2$HullArea <- st_area(Group2)
Group2Hull <- st_convex_hull(Group2)

Group1torns$mag <- as.numeric(Group1torns$mag)
Group1torns$mag2 <- cut(Group1torns$mag, breaks=c(-1, 0, 1, 2, 3, 4, 5))
Group2torns$mag <- as.numeric(Group2torns$mag)
Group2torns$mag2 <- cut(Group2torns$mag, breaks=c(-1, 0, 1, 2, 3, 4, 5))
```

```{r}
G2 <- tm_shape(stateBorders) + 
  tm_borders(col = "gray70") +
tm_shape(Group2Hull) + 
  tm_borders(col = "gray15", 
             alpha = 1, 
             lwd = 2) +
  tm_scale_bar(color.dark = "gray70", 
               width = .2, 
               size = 1, 
               lwd = 2, 
               position = c("left","bottom")) +
    tm_compass(color.dark = "gray70", 
             size = 5, 
             lwd = 2, 
             position = c("left","top")) + 
    tm_format("World", 
              attr.position = c("left", "top"),
              legend.frame = FALSE,
              inner.margins = c(.2, .1, .2, .1)) +
    tm_layout(legend.bg.color = "white", 
            legend.text.size = .75) + 
  tm_shape(Group2torns, 
         projection = "+proj=merc +lon_0=0 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs", 
         is.master = TRUE) +
    tm_symbols(size = 3, 
               col = "mag2", 
               n = 6, 
               palette = cr, 
               alpha = 0.8, 
               border.alpha = 0, 
               labels = c("0", "1", "2", "3", "4", "5"), 
               title.col = "EF Rating") +
    tm_layout(title = "June 6, 1999 \n 13 tornadoes", 
              title.position = c("center", "top"), 
              legend.title.size = 1.4,
              legend.position = c("right", "bottom"), 
              legend.stack = "horizontal",
              legend.frame = FALSE, 
              legend.text.size = 1.2, 
              legend.width = -0.15, 
              title.size = 1.5)
G2
```

```{r}
tmap_arrange(G1, G2)
```

```{r}
June6_tornadoes <- rbind(Group1torns, Group2torns)
June6 <- rbind(Group1, Group2)
June6$HullArea <- st_area(June6)
June6 <- st_convex_hull(June6)

June6_tornadoes <- st_transform(June6_tornadoes, 
  crs = "+proj=lcc +lat_0=50 +lon_0=-107 +lat_1=50 +lat_2=50 +x_0=0 +y_0=0 +R=6371200 +units=m +no_defs ")
```

Get the centroid (central point of the tornado activity) for each big day. 
```{r, eval = FALSE}
June6Centroids.df <- st_centroid(June6)
June6Centroids.df$groupArea <- st_area(st_convex_hull(June6))
June6Centroids.df$groupDensity <- June6Centroids.df$nT/June6Centroids.df$groupArea
```

```{r}
library(xts)
June6$StartTime_UTC <- force_tz(June6$StartTime_UTC, tzone = "UTC")
June6$NARRtime <- (align.time(June6$StartTime_UTC, n = (60 * 60 * 3)) - 3600 * 3)
```

Split the NARR date and time into their individual variables. Then bind the columns for BigDays.sfdfT. NOTE: cannot do a mutate because 00Z produces NAs. DON'T USE!
```{r, eval = FALSE}
NARRday = format(as.POSIXct(strptime(June6$NARRtime,"%Y-%m-%d %H:%M:%S",tz="")) ,format = "%Y/%m/%d")
NARRZtime = format(as.POSIXct(strptime(June6$NARRtime,"%Y-%m-%d %H:%M:%S",tz="")) ,format = "%H")

June6 <- cbind(June6, NARRday, NARRZtime)
```

Create a downloadable string of information for the varying NARR times. 
```{r, eval = FALSE}
June6 <- June6 %>%
  mutate(YrMoDa = gsub("/", "", NARRday),
         slug = paste0("merged_AWIP32.",YrMoDa, NARRZtime),
         slug2 = paste0("merged_AWIP32.",YrMoDa))
```

```{r}
avgCAPE <- numeric()
avgsbCAPE <- numeric()
avgDEW <- numeric()
avgMR <- numeric()
avgHLCY <- numeric()
avgCIN <- numeric()
avgsbCIN <- numeric()
avgUSTM <- numeric()
avgVSTM <- numeric()
avgBS_deep <- numeric()
avgBS_shallow <- numeric()
avgSM <- numeric()
avgRATIO <- numeric()
avgLCL <- numeric()
maxCAPE <- numeric()
maxsbCAPE <- numeric()
maxDEW <- numeric()
maxMR <- numeric()
maxHLCY <- numeric()
minCIN <- numeric()
minsbCIN <- numeric()
maxUSTM <- numeric()
maxVSTM <- numeric()
maxBS_deep <- numeric()
maxBS_shallow <- numeric()
maxSM <- numeric()
maxLCL <- numeric()
minLCL <- numeric()
 
for(i in 1:2){
  print(i)
   rb <- brick(paste0("/Users/zoeschroder/Desktop/Projects/Torn_Freq/", June6$slug2[i], "/", June6$slug[i])) #<-- this is for varying NARR times
  CAPE <- raster(rb, layer = 375)
  sbCAPE <- raster(rb, layer = 315)
  DEW <- raster(rb, layer = 290)
  MR <- raster(rb, layer = 289)
  HLCY <- raster(rb, layer = 323)
  CIN <- raster(rb, layer = 376)
  sbCIN <- raster(rb, layer = 316)
  USTM <- raster(rb, layer = 324)
  VSTM <- raster(rb, layer = 325)
  UGRD500 <- raster(rb, layer = 117) 
  VGRD500 <- raster(rb, layer = 118) 
  UGRD850 <- raster(rb, layer = 206) 
  VGRD850 <- raster(rb, layer = 207)
  UGRDsfc <- raster(rb, layer = 293) 
  VGRDsfc <- raster(rb, layer = 294)  
  LCL <- raster(rb, layer = 319)
  SM <- sqrt(USTM^2 + VSTM^2)
  RATIO <- CAPE/abs(CIN)
  BS_deep <- sqrt(((UGRD500 - UGRDsfc)**2) + ((VGRD500 - VGRDsfc)**2))
  BS_shallow <- sqrt(((UGRD850 - UGRDsfc)**2) + ((VGRD850 - VGRDsfc)**2))
  avgCAPE <- c(avgCAPE, as.numeric(raster::extract(CAPE, June6[i, ], fun = mean)))
  avgsbCAPE <- c(avgsbCAPE, as.numeric(raster::extract(sbCAPE, June6[i, ], fun = mean)))
  maxCAPE <- c(maxCAPE, as.numeric(raster::extract(CAPE, June6[i, ], fun = max)))
  maxsbCAPE <- c(maxsbCAPE, as.numeric(raster::extract(sbCAPE, June6[i, ], fun = max)))
  avgDEW <- c(avgDEW, as.numeric(raster::extract(DEW, June6[i, ], fun = mean)))
  maxDEW <- c(maxDEW, as.numeric(raster::extract(DEW, June6[i, ], fun = max)))
  avgMR <- c(avgMR, as.numeric(raster::extract(MR, June6[i, ], fun = mean)))
  maxMR <- c(maxMR, as.numeric(raster::extract(MR, June6[i, ], fun = max)))
  avgHLCY <- c(avgHLCY, as.numeric(raster::extract(HLCY, June6[i, ], fun = mean)))
  maxHLCY <- c(maxHLCY, as.numeric(raster::extract(HLCY, June6[i, ], fun = max)))
  avgCIN <- c(avgCIN, as.numeric(raster::extract(CIN, June6[i, ], fun = mean)))
  avgsbCIN <- c(avgsbCIN, as.numeric(raster::extract(sbCIN, June6[i, ], fun = mean)))
  minCIN <- c(minCIN, as.numeric(raster::extract(CIN, June6[i, ], fun = min)))
  minsbCIN <- c(minsbCIN, as.numeric(raster::extract(sbCIN, June6[i, ], fun = min)))
  avgUSTM <- c(avgUSTM, as.numeric(raster::extract(USTM, June6[i, ], fun = mean)))
  maxUSTM <- c(maxUSTM, as.numeric(raster::extract(USTM, June6[i, ], fun = max)))
  avgVSTM <- c(avgVSTM, as.numeric(raster::extract(VSTM, June6[i, ], fun = mean)))
  maxVSTM <- c(maxVSTM, as.numeric(raster::extract(VSTM, June6[i, ], fun = max)))
  avgSM <- c(avgSM, as.numeric(raster::extract(SM, June6[i, ], fun = mean)))
  maxSM <- c(maxSM, as.numeric(raster::extract(SM, June6[i, ], fun = max)))
  avgRATIO <- c(avgRATIO, as.numeric(raster::extract(RATIO, June6[i, ], fun = mean)))
  avgBS_deep <- c(avgBS_deep, as.numeric(raster::extract(BS_deep, June6[i, ], fun = mean)))
  maxBS_deep <- c(maxBS_deep, as.numeric(raster::extract(BS_deep, June6[i, ], fun = max)))  
  avgBS_shallow <- c(avgBS_shallow, as.numeric(raster::extract(BS_shallow, June6[i, ], fun = mean)))
  maxBS_shallow <- c(maxBS_shallow, as.numeric(raster::extract(BS_shallow, June6[i, ], fun = max)))
  avgLCL <- c(avgLCL, as.numeric(raster::extract(LCL, June6[i,], fun = mean)))
  maxLCL <- c(maxLCL, as.numeric(raster::extract(LCL, June6[i,], fun = max)))
  minLCL <- c(minLCL, as.numeric(raster::extract(LCL, June6[i,], fun = min)))
}
```

Add environmental data values to the group day means data frame.
```{r}
June6$avgCAPE <- avgCAPE
June6$avgsbCAPE <- avgsbCAPE
June6$maxCAPE <- maxCAPE
June6$maxsbCAPE <- maxsbCAPE
June6$avgDEW <- avgDEW
June6$maxDEW <- maxDEW
June6$avgMR <- avgMR
June6$maxMR <- maxMR
June6$avgHLCY <- avgHLCY
June6$maxHLCY <- maxHLCY
June6$avgCIN <- avgCIN
June6$avgsbCIN <- avgsbCIN
June6$minCIN <- minCIN
June6$minsbCIN <- minsbCIN
June6$avgUSTM <- avgUSTM
June6$maxUSTM <- maxUSTM
June6$avgVSTM <- avgVSTM
June6$maxVSTM <- maxVSTM
June6$avgBS_deep <- avgBS_deep
June6$maxBS_deep <- maxBS_deep
June6$avgBS_shallow <- avgBS_shallow
June6$maxBS_shallow <- maxBS_shallow
June6$avgRATIO <- avgRATIO
June6$avgSM <- avgSM
June6$maxSM <- maxSM
June6$minLCL <- minLCL
June6$maxLCL <- maxLCL
June6$avgLCL <- avgLCL
```

```{r}
x<- June6 %>%
  group_by(nT) %>%
  summarize(maxCAPE = maxCAPE,
            maxHLCY = maxHLCY,
            maxDLBS = maxBS_deep,
            maxSLBS = maxBS_shallow,
            minCIN = minCIN)
x
```

```{r}
CAPE_June6 <- crop(CAPE, extent(June6))
CAPE_extent<- mask(CAPE_June6, June6)
plot(CAPE_extent)
maxCAPE <- which.max(CAPE_extent) #Returns a pixel number
#Test that this max value equals the one in BigDays.sfdfT
test <- getValues(CAPE_extent) 
test<-as.matrix(test, ncol=1)
```

```{r}
CAPEmaxpos <- xyFromCell(CAPE_extent, maxCAPE)
xy <- data.frame(CAPEmaxpos)
CAPE_latlon <- data.frame(lon=xy$x, lat=xy$y)
print(CAPE_latlon)
CAPE_latlon <- SpatialPoints(CAPE_latlon)
proj4string(CAPE_latlon) = CRS("+proj=lcc +lat_1=50 +lat_2=50 +lat_0=50 +lon_0=-107 +x_0=0 +y_0=0 +a=6371200 +b=6371200 +units=m +no_defs")
```

```{r}
#install.packages("USAboundariesData")
counties <- us_counties()
states <- us_states()
```

```{r, eval = FALSE}
p1 <- tm_shape(CAPE_extent) +
  tm_raster(title = "",  n = 6, palette = "Greys") +
  tm_format(title = expression(paste("CAPE [J ", kg^-1, "]")), "World", legend.position = c("left", "bottom"),
                   attr.position = c("left", "bottom"),
                   legend.frame = FALSE,
                   inner.margins = c(.1, 0.18, .1, .18), #bottom, left, top
                    legend.text.size = 1, legend.width = -0.28, legend.title.size=1, legend.bg.color = "white", title.size = 1.4) +
#tm_shape(counties) +
  #tm_borders(col = "grey") +
  tm_scale_bar(width = 0.3, size = 0.8, position = c("right", "top"), color.dark = "gray70") +
tm_shape(states) +
  tm_borders() +
tm_shape(June6, is.master = TRUE, projection = merc) +
  tm_borders(col = "black", lwd = 3)  +
#tm_shape(June6tornadoes) +
#  tm_symbols(size = 1.25, col = "black", shape = 24) +
tm_shape(CAPE_latlon) + 
  tm_symbols(size = 1.4, col = "black", shape = 22) + 
    tm_shape(June6tornadoes, 
         projection = "+proj=merc +lon_0=0 +k=1 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs", 
         is.master = TRUE) +
    tm_symbols(size = 3)
p1
```

```{r}
st_crs(CAPE)
```















```{r}
#<-- this is for varying NARR times
for(i in 1:1){
  print(i)
   rb <- brick(paste0("/Users/zoeschroder/Desktop/Projects/Torn_Freq/", June6$slug2[i], "/", June6$slug[i]))
  CAPE <- raster(rb, layer = 375)
  HLCY <- raster(rb, layer = 323)
  CIN <- raster(rb, layer = 376)
  UGRD500 <- raster(rb, layer = 117) 
  VGRD500 <- raster(rb, layer = 118) 
  UGRDsfc <- raster(rb, layer = 293) 
  VGRDsfc <- raster(rb, layer = 294)     
  BS <- sqrt(((UGRD500 - UGRDsfc)**2) + ((VGRD500 - VGRDsfc)**2))
}

for(i in 2:2){
  print(i)
   rb <- brick(paste0("/Users/zoeschroder/Desktop/Projects/Torn_Freq/", June6$slug2[i], "/", June6$slug[i]))
  CAPE2 <- raster(rb, layer = 375)
  HLCY2 <- raster(rb, layer = 323)
  CIN2 <- raster(rb, layer = 376)
  UGRD5002 <- raster(rb, layer = 117) 
  VGRD5002 <- raster(rb, layer = 118) 
  UGRDsfc2 <- raster(rb, layer = 293) 
  VGRDsfc2 <- raster(rb, layer = 294)     
  BS2 <- sqrt(((UGRD5002 - UGRDsfc2)**2) + ((VGRD5002 - VGRDsfc2)**2))
}
```
**Convective Available Potential energy **
```{r}
June6 <- st_transform(June6, 
  crs = "+proj=lcc +lat_1=50 +lat_2=50 +lat_0=50 +lon_0=-107 +x_0=0 +y_0=0 +a=6371200 +b=6371200 +units=m +no_defs")

J6_1 <- June6[1,]
CAPE_June6 <- crop(CAPE, extent(J6_1))
CAPE_extent<- mask(CAPE_June6, J6_1)
plot(CAPE_extent)
maxCAPE <- which.max(CAPE_extent) #Returns a pixel number
#Test that this max value equals the one in BigDays.sfdfT
test <- getValues(CAPE_extent) 
test<-as.matrix(test, ncol=1)
```

```{r}
counties <- us_counties()
states <- us_states()
```

```{r, eval = FALSE}

p1 <- tm_shape(CAPE_extent) +
  tm_raster(title = "",  n = 6, palette = "Greys") +
  tm_format(title = expression(paste("CAPE [J ", kg^-1, "]")), "World", legend.position = c("right", "bottom"),
                   attr.position = c("right", "bottom"),
                   legend.frame = FALSE,
                   inner.margins = c(.3, 0.3, .3, .3), #bottom, left, top
                    legend.text.size = 1, legend.width = -0.28, legend.title.size=1, legend.bg.color = "white", title.size = 1.4) +
#tm_shape(counties) +
#  tm_borders(col = "grey") +
#  tm_scale_bar(width = 0.3, size = 0.8, position = c("right", "top"), color.dark = "gray70") +
tm_shape(stateBorders, projection = merc, is.master=TRUE) +
  tm_borders() +
tm_shape(J6_1) +
  tm_borders(col = "black", lwd = 3)   +
tm_shape(Group1torns, 
         is.master = TRUE) +
    tm_symbols(size = 3)#+
#tm_shape(June6centroid) +
#  tm_symbols(size = 1.25, col = "black", shape = 24) +
#tm_shape(CAPE_latlon) + 
#  tm_symbols(size = 1.4, col = "black", shape = 22)
p1
```





```{r}
cluster3 <- BigDays.sfdfT %>%
  filter(ID == 200802053876)

cluster3 <- st_convex_hull(cluster3)

cluster3torns <- All_Tornadoes %>%
  filter(ID == 200802053876) 

cluster3 %>%
  summarize(Area = HullArea/(10**6),
            Duration = Duration/3600)

cluster3torns$mag <- as.numeric(cluster3torns$mag)
cluster3torns$mag2 <- cut(cluster3torns$mag, breaks=c(-1, 0, 1, 2, 3, 4, 5))
```

```{r}
C <- tm_shape(stateBorders) + 
  tm_borders(col = "gray70") +
tm_shape(cluster3) + 
  tm_borders(col = "gray15", 
             alpha = 1, 
             lwd = 2) +
  tm_scale_bar(color.dark = "gray70", 
               width = .3, 
               size = 1, 
               lwd = 2, 
               position = c("left","bottom")) +
    tm_compass(color.dark = "gray70", 
             size = 5, 
             lwd = 2, 
             position = c("left","top")) + 
    tm_format("World", 
              attr.position = c("left", "top"),
              legend.frame = FALSE,
              inner.margins = c(.1, .1, .2, .1)) +
    tm_layout(legend.bg.color = "white", 
            legend.text.size = .75) + 
  tm_shape(cluster3torns, 
         projection = "merc", 
         is.master = TRUE) +
    tm_symbols(size = 3, 
               col = "mag2", 
               n = 6, 
               palette = cr, 
               alpha = 0.8, 
               border.alpha = 0, 
               labels = c("0", "1", "2", "3", "4", "5"), 
               title.col = "EF Rating") +
    tm_layout(title = "February 5, 2008 \n 85 tornadoes", 
              title.position = c("center", "top"), 
              legend.title.size = 1.4,
              legend.position = c("right", "bottom"), 
              legend.stack = "horizontal",
              legend.frame = FALSE, 
              legend.text.size = 1.2, 
              legend.width = -0.2, 
              title.size = 1.5)
C  
```

```{r}
#Extract the big day using the unique ID created. 
cluster4 <- BigDays.sfdfT %>%
  filter(ID == 201104274630)

#Generate a convex hull around the big day. 
cluster4 <- st_convex_hull(cluster4)

#Extract all tornadoes that are in the biggestday 
cluster4torns <- All_Tornadoes %>%
  filter(ID == 201104274630) 

cluster4torns$mag <- as.numeric(cluster4torns$mag)
cluster4torns$mag2 <- cut(cluster4torns$mag, breaks=c(-1, 0, 1, 2, 3, 4, 5))
```

```{r}
D <- tm_shape(stateBorders) + 
  tm_borders(col = "gray70") +
tm_shape(cluster4) + 
  tm_borders(col = "gray15", 
             alpha = 1, 
             lwd = 2) +
  tm_scale_bar(color.dark = "gray70", 
               width = .3, 
               size = 1, 
               lwd = 2, 
               position = c("left","bottom")) +
    tm_compass(color.dark = "gray70", 
             size = 5, 
             lwd = 2, 
             position = c("left","top")) + 
    tm_format("World", 
              attr.position = c("left", "top"),
              legend.frame = FALSE,
              inner.margins = c(.15, .1, .2, .1)) +
    tm_layout(legend.bg.color = "white", 
            legend.text.size = .75) + 
  tm_shape(cluster4torns, 
         projection = "merc", 
         is.master = TRUE) +
    tm_symbols(size = 3, 
               col = "mag2", 
               n = 6, 
               palette = cr, 
               alpha = 0.8, 
               border.alpha = 0, 
               labels = c("0", "1", "2", "3", "4", "5"), 
               title.col = "EF Rating") +
    tm_layout(title = "April 27, 2011 \n 173 tornadoes", 
              title.position = c("center", "top"), 
              legend.title.size = 1.4,
              legend.position = c("right", "bottom"), 
              legend.stack = "horizontal",
              legend.frame = FALSE, 
              legend.text.size = 1.2, 
              legend.width = -0.2, 
              title.size = 1.5)
  
D
```

```{r}
tmap_arrange(A, B, C, D)
```
`Figure 1: Examples of four tornado clusters used in this study. Each point is the tornado genesis location colored by the assigned EF rating. The black line is the spatial extent of tornadoes for that convective day defined by the minimum convex hull.` \label{fig:Clusters}

*How long was the largest(smallest) cluster? How large was the largest(smallest)cluster?*
```{r}
cluster1 %>%
  summarize(Area = HullArea/(10**6),
            Duration = Duration/3600)
#Area: 33 358.78 sq. km
#Duration: 3.967 hours

cluster4 %>%
  summarize(Area = HullArea/(10**6),
            Duration = Duration/3600)
#Area: 1 064 337 sq. km
#Duration: 23.8 hours
```

Other big cluster statistics.
```{r}
df <- BigDays.sfdfT %>% 
  st_drop_geometry() %>%
  mutate(TorPerHour = nT/as.numeric(Duration) * 3600) %>%
  select(cDate, nT, Duration, TorPerHour) %>%
  arrange(desc(TorPerHour))

df <- BigDays.sfdfT %>% 
  st_drop_geometry() %>%
  mutate(TorPerHour = nT/as.numeric(Duration) * 3600)
```

The thermo variables (e.g., minLCL) are somewhat better correlated to the rate of tornado production `TorPerHour` than to the number of tornadoes `nT`. The opposite is the case for the kinematic variables.

There is a distinct seasonality to the occurrence of tornado clusters (Fig.~\ref{fig:ClusterByWeek}). The empirical seven-day probability of at least one cluster is about 30\% for much of the year except during March, April and May when the weekly probabilities approach 80\%. The average number of tornadoes per cluster is less variable.

*Separate the clusters by week of the year.*
```{r}
TornsbyWeek <- BigDays.sfdfT %>% 
  group_by(week = week(cDate)) %>%
  summarize(totalclusters = n(),
            numtorn = sum(nT),
            avgsize = numtorn / totalclusters,
            tornrate = mean(TorPerHour), 
            torndens = mean(TorPerKm), 
            avgarea = mean(HullArea * (10^-6)), 
            avgcas = mean(GroupDayCas),
            avgcasperkm = mean((GroupDayCas/((totalPOP+1)/1000000))))
```

**For each week sum the number of clusters and divide by the number of years to get the rate lambda. Then take 1-dpois(lambda) * 100 to get the probability**

`Empirical Probability of getting a cluster by week`
```{r}
Years <- 2018-1994 + 1

lambdas <- TornsbyWeek$totalclusters / Years
probs <- (1 - dpois(0, lambdas)) * 100

TornsbyWeek <- cbind(TornsbyWeek, probs)
```

`Get the week labels for the data`
```{r}
x.Date <- as.Date(paste(rep(1994:2018, each = 12), rep(1:12, 2), 1, sep = "-"))
library(zoo)
x <- zoo(rnorm(24), x.Date)
times <- time(x)
ticks <- as.data.frame(x = seq(times[1], times[length(times)], by = "weeks"))

week <- as.data.frame(ticks[1:53,])
  
months <- as.data.frame(format(week, "%b"))
Mo <- as.data.frame(format(week, "%m"))
day <- as.data.frame(format(week, "%d"))

dat <- as.data.frame(cbind(week, Mo, months, day))
colnames(dat) <- c("Week", "Mo", "Month", "Day") 

dat <- dat %>%
  group_by(Month, Day, Mo) %>%
  summarize(count = n(),
            Week = paste0(Month, " ", Day))


dat <- dat[order(dat$Mo),]
```

```{r}
labels = dat$Week
```

```{r}
A <- ggplot(TornsbyWeek, (aes(week))) +
  #geom_smooth(aes(x = week, y = probs/100), span = .5, se = FALSE, color = "gray70", size = 1) +
  geom_line(aes(y = probs/100), color = "black", lwd = 1) +
  scale_x_continuous(expand = c(0, 0), breaks = c(seq(1,53,3)), limits = c(1, 53), labels = labels[seq(1, length(labels), 3)]) +
  scale_y_continuous(limits = c(0, 1)) + 
#  geom_smooth(aes(x = week, y = probs/100), span = .5, se = FALSE, color = "gray70", size = 1) +
  theme_bw() +
  xlab("") +
  ylab("Probability of a cluster\n ")

A <- A + theme(panel.grid = element_blank(), axis.title.y = element_text(colour = "black"), axis.text.y = element_text(color = "black"),  axis.text.x = element_text(angle = 45, hjust = 1), axis.text = element_text(size = 12), axis.title=element_text(size=14)) + ggtitle("A")
```
Figure 2: Probability of a Cluster


```{r}
B <- ggplot(TornsbyWeek, (aes(week))) +
  #geom_smooth(aes(x = week, y = avgsize), span = .5, se = FALSE, color = "gray70", size = 1) +
  geom_line(aes(y = avgsize), color = "black", lwd = 1) +
  scale_x_continuous(expand = c(0, 0), breaks = c(seq(1,53,3)), limits = c(1, 53), labels = labels[seq(1, length(labels), 3)]) +
  scale_y_continuous(breaks = c(seq(0,50,10)), limits = c(0, 50)) + 
  theme_bw() +
  xlab("") +
  ylab("Number of tornadoes\n ")

B <- B + theme(panel.grid = element_blank(), axis.title.y = element_text(colour = "black"), axis.text.y = element_text(color = "black"),  axis.text.x = element_text(angle = 45, hjust = 1), axis.text = element_text(size = 12), axis.title=element_text(size=14)) + ggtitle("B")
```

```{r}
C <- ggplot(TornsbyWeek, (aes(week))) +
  #geom_smooth(aes(x = week, y = as.numeric(avgcasperkm)), span = .5, se = FALSE, color = "gray70", size = 1) +
  geom_line(aes(y = as.numeric(avgcasperkm)), color = "black", lwd = 1) +
  scale_x_continuous(expand = c(0, 0), breaks = c(seq(1,53,3)), limits = c(1, 53), labels = labels[seq(1, length(labels), 3)]) +
  #scale_y_continuous(breaks = c(seq(0,150,25)), limits = c(0, 150)) + 
  theme_bw() +
  xlab("") +
  ylab("Number of casualties\n")

C <- C + theme(panel.grid = element_blank(), axis.title.y = element_text(colour = "black"), axis.text.y = element_text(color = "black"),  axis.text.x = element_text(angle = 45, hjust = 1), axis.text = element_text(size = 12), axis.title=element_text(size=14)) + ggtitle("C")
C
```


```{r}
ggarrange(A, B, C, ncol = 1)
```

Fig 3: Align the horizontal axis Jan 1st shifted in 1st Facet Wrap align them. Gonna have to play with axis title. Don't need percentages. Axis labels. A: Probability of a cLuster (remove 2nd row) B: Number of tornadoes (Remove capital cluster) C: Number of casualties 
Last panel casualties per population (Northern plains with fewer people of the dip? Normalize the data by population.) avg number of casualties per 1000 people per week. Take a look. Potentially remove grid lines. 
## Environmental Data ##

Environmental conditions for producing tornadoes are well known and include high values of convective available potential energy, convective inhibition, storm-relative helicity, and bulk shear \citep{Brooks1994, RasmussenandBlanchard1998, TippettEtAl2012, TippettEtAl2014, ElsnerSchroder2019}. We obtain the corresponding atmospheric variables associated with these environmental conditions from the National Centers for Atmospheric Research's North American Regional Reanalysis (NARR) which is supported by the National Centers for Environmental Prediction. Each atmospheric variable has numeric values given on a 32-km raster grid and the gridded values are available in three-hour increments starting at 00 UTC.

We select variables at the nearest three-hour time {\it prior} to the occurrence of the first tornado in the cluster. For example, if the first tornado in a cluster occurs at 16:30 UTC we use the atmospheric variables given at 15 UTC. This selection criteria results in a sample of the environment that is less contaminated by the deep convection itself but at a cost that underestimates the severity in cases where rapid increases in conditions favorable for tornadoes occur. We find that roughly 60\% of all clusters have the initial tornado between 18 and 00 UTC (Table~\ref{tab:Ztimes}). We also find that cluster size is largest, on average, for clusters with the first tornado occurring between 15 and 18 UTC.
```{r}
 BigDays.sfdfT %>%
  group_by(NARRZtime) %>%
  summarize(count = n(),
            TornTot = sum(nT), 
            AvgClusSize = TornTot/count)

#What percentage of convective days start between 18Z and 00Z? 
(210+249) / 767
#~60%
```
`Table 1: Each cluster is categorized by the closest three-hour time (defined by the NARR data) prior to the first tornado.` \label{tab:Ztimes}

Environmental variables considered include convective available potential energy and convective inhibition as computed using the near-surface layer (0 to 180 mb above the ground level) (layer 375,376), storm-relative helicity as computed from winds in the 0 to 3000 m above the ground (layer 323), the $u$ and $v$ components of storm motion as computed from winds in the 0 to 6000 m above the ground (layer 324, 325), and the $u$ and $v$ wind components estimated at 1000 mb (layer 260, 261) and at 500 mb (layer 117, 118). Additionally we consider bulk shear that we compute as the square root of the sum of the squared differences between the $u$ and $v$ wind components at these two levels.

We take the highest (lowest for CIN) value across the grid of values within the area defined by the cluster's convex hull. This is done to capture the extremes of the environmental condition. We note that the May 30, 2003 cluster is missing storm-relative helicity and so it is removed from further consideration. Across the remaining 767 clusters the mean value of regionally highest CAPE is 2~225~J~kg$^{-1}$ and the mean value of regionally lowest CIN is $-$114~J~kg$^{-1}$ (Table \ref{tab:VarValues}). The range of highest bulk shear values is between 5.6 and 47.9 m~s$^{-1}$ and the range of highest storm relative helicity is between 34.3 and 1027 m$^{2}$~s$^{-2}$. Cluster areas range between 361 and 1~064~337~km$^{2}$ with an average of 167~990~km$^{2}$.

*Remove the day with missing helicity values. This day is May 30, 2003.*
```{r, eval = FALSE}
BigDays.sfdfT <- BigDays.sfdfT %>%
  filter(ID != 200305302651)
```

*Get the maximum, minimum, and average of the environmetal variables. Create a table displaying this information.*
```{r}
maximum <- as.matrix(c(max(BigDays.sfdfT$maxCAPE), max(BigDays.sfdfT$maxVSTM), max(BigDays.sfdfT$maxBS_deep), max(BigDays.sfdfT$maxBS_shallow), max(BigDays.sfdfT$maxHLCY), (max(BigDays.sfdfT$HullArea)*1e-6), max(BigDays.sfdfT$minCIN), max(BigDays.sfdfT$maxUSTM)), ncol = 1)

minimum <- as.matrix(c(min(BigDays.sfdfT$maxCAPE), min(BigDays.sfdfT$maxVSTM), min(BigDays.sfdfT$maxBS_deep), min(BigDays.sfdfT$maxBS_shallow), min(BigDays.sfdfT$maxHLCY), (min(BigDays.sfdfT$HullArea)*1e-6), min(BigDays.sfdfT$minCIN), min(BigDays.sfdfT$maxUSTM)), ncol = 1)

average <- as.matrix(c(mean(BigDays.sfdfT$maxCAPE), mean(BigDays.sfdfT$maxVSTM), mean(BigDays.sfdfT$maxBS_deep), mean(BigDays.sfdfT$maxBS_shallow), mean(BigDays.sfdfT$maxHLCY), (mean(BigDays.sfdfT$HullArea)*1e-6), mean(BigDays.sfdfT$minCIN), mean(BigDays.sfdfT$maxUSTM)), ncol = 1)

Variable <- as.matrix(c("Convective Available Potential Energy", "Northward Storm Motion", "Deep-Layer Bulk Shear", "Shallow-Layer Bulk Shear", "Helicity", "Outbreak Area", "CIN", "Eastward Storm Motion"), ncol = 1)

abbr <- as.matrix(c("CAPE", "VSTM", "DLBS","SLBS", "HLCY", "AREA", "CIN", "USTM"), ncol = 1)

env_variation <- cbind(Variable, abbr, maximum, minimum, average)
colnames(env_variation) <- c("Variable Name", "Abbreviation", "Maximum", "Minimum", "Average")

xtable(as.data.frame((env_variation))) #round to sig fig
```
`Table 2: The range and average highest (lowest for CIN) value of the environmental variables across the 767 tornado clusters used in the study.` \label{tab:VarValues}

```{r}
cor.test(BigDays.sfdfT$nT, BigDays.sfdfT$HullArea)
#0.567

cor(BigDays.sfdfT$totalPOP, BigDays.sfdfT$HullArea)
#0.8185096

cor(BigDays.sfdfT$Lat, BigDays.sfdfT$maxVSTM)
#-0.2278864

cor.test(BigDays.sfdfT$maxDEW, BigDays.sfdfT$maxMR)
#0.979

cor(BigDays.sfdfT$maxBS_shallow, BigDays.sfdfT$maxHLCY)
#0.7556492
```

```{r}
(plot_nT <- ggplot(BigDays.sfdfT, aes(nT)) + 
  geom_histogram(boundary = 50, 
                 bins = 43, 
                 alpha = 0.9, 
                 color = "white", 
                 fill = "Grey40",
                 size = 0.1) +
  scale_x_continuous(expand = c(0,0), limits = c(9,50)) +
  #scale_x_log10() + 
  xlab("Number of Tornadoes") +
  scale_y_continuous(expand = c(0,0), breaks = c(0, 25, 50, 75, 100), labels = c("0", "25", "50", "75", "100"), limits = c(0, 100)) +
  ylab("Number of Clusters") + 
  ggtitle("A") +
  theme_bw() +
  theme(text = element_text(size=12), plot.background = element_rect(color = "grey40"), panel.border = element_rect(color = "white"), plot.margin=unit(c(0.5, 0.5, 0.5, 0.5),"cm")))

(plot_cas <- ggplot(BigDays.sfdfT, aes(GroupDayCas)) + 
  geom_histogram(boundary = 50, 
                 bins = 26, 
                 alpha = 0.9, 
                 color = "white", 
                 fill = "Grey40",
                 size = 0.1) +
  scale_x_continuous(expand = c(0,0),limits = c(0,50)) +
  #scale_x_log10() + 
  xlab("Number of Casualties") +
  scale_y_continuous(expand = c(0,0), breaks = c(0, 100, 200, 300, 400), labels = c("0", "100", "200", "300", "400"), limits = c(0, 400)) +
  ylab("Number of Clusters") + 
  ggtitle("B") +
  theme_bw() +
  theme(text = element_text(size=12), plot.background = element_rect(color = "grey40"), panel.border = element_rect(color = "white"), plot.margin=unit(c(0.5, 0.5, 0.5, 0.5),"cm")))
```

```{r}
ggarrange(plot_nT, plot_cas, ncol = 2)
```
## Model Selection

I think we should simplify things by using log-linear models. Cluster size, cluster area, and tornado production rate.

Consider only CAPE, CIN, BS (deep & shallow)

## Estimate the Number of Tornadoes
```{r}
library(MASS)

modelInitial <- glm.nb(nT ~ A + Lat + Lon + Year + CAPE + CIN + DLBS + SLBS, data = BigDays.sfdfT)
summary(modelInitial)

modelInitialPoisson <- glm(nT ~ A + Lat + Lon + CAPE + CIN + DLBS + SLBS, family = "poisson", data = BigDays.sfdfT)
summary(modelInitialPoisson)

modelFinal <- glm.nb(nT ~ A + CAPE + DLBS + SLBS, data = BigDays.sfdfT)
summary(modelFinal)

(exp(coef(modelFinal)) - 1) * 100

summary(lm(log(nT) ~ HullArea + maxCAPE + maxBS_deep + maxBS_shallow, data = BigDays.sfdfT))


hist(resid(modelFinal))
range(exp(predict(modelFinal)))
plot(log(BigDays.sfdfT$nT), predict(modelFinal))
cor(BigDays.sfdfT$nT, predict(modelFinal, type = "response"))
```

```{r}
(plotresid_nT <- ggplot(modelFinal, aes(.resid)) + 
  geom_histogram(bins = 30, 
                 alpha = 0.9, 
                 color = "white", 
                 fill = "Grey40",
                 size = 0.1) +
   xlab("Residuals")  +
  ylab("Count") + 
 # ggtitle("B") +
  theme_bw() +
  theme(text = element_text(size=12), plot.background = element_rect(color = "grey40"), panel.border = element_rect(color = "white"), plot.margin=unit(c(0.5, 0.5, 0.5, 0.5),"cm")))
```

```{r, eval = FALSE}
modelglmer.nb <- glmer.nb(nT ~ scale(HullArea) + scale(maxCAPE) + scale(maxBS_deep) + scale(maxBS_shallow) + (1|Season), data = BigDays.sfdfT)
summary(modelglmer.nb) # no convergence if interaction term is included

summary(glm.nb(nT ~ scale(HullArea) + scale(maxCAPE) + scale(avgCIN) + scale(maxBS_deep) + scale(maxBS_shallow), data = BigDays.sfdfT))

modelFinal <- glm.nb(nT ~ HullArea + maxCAPE + maxBS_deep + maxBS_shallow, data = BigDays.sfdfT[BigDays.sfdfT$Mo %in% c(10, 11),])
summary(modelFinal)
```

```{r}
predsnT <- (predict(modelFinal))
BigDays.sfdfT = cbind(BigDays.sfdfT, predsnT)

cc <- scales::seq_gradient_pal("skyblue", "blue")(seq(0,1,length.out=12))

ggplot(BigDays.sfdfT, aes(x = log(nT), y = predsnT)) +
  geom_point(size = 4,  show.legend = FALSE, stroke = 0, alpha = 0.8, color = "Grey40") +
      #scale_color_continuous()
      scale_color_manual(values = cc) +
      #scale_colour_gradient(low = "Grey", high = "Grey70") +
      geom_abline() + 
      ylab("Estimated Tornadoes") + 
      xlab("Actual Tornadoes") +
      scale_x_log10(breaks = c(2.3, 3.2, 3.9 ,4.6, 5.01), labels = c("10", "25", "50", "100", "150")) +
      scale_y_log10(limits = c(2.3, 5.03), breaks = c(2.3, 3.2, 3.9 ,4.6, 5.01), labels = c("10", "25", "50", "100", "150")) +
      theme_minimal() + 
        theme(text = element_text(size=10), plot.background = element_rect(colour = 'grey40'))#, panel.border = element_rect(color = "Grey40")) 
```
## Model for Casualties

```{r}
modelInitialC <- glm.nb(GroupDayCas ~ totalPOP + maxCAPE + minCIN + maxBS_deep + maxBS_shallow + Lat + Lon + Year, data = BigDays.sfdfT)
summary(modelInitialC)

modelFinalC <- glm.nb(GroupDayCas ~ totalPOP + maxCAPE + maxBS_deep + maxBS_shallow + Lat + Lon + Year, data = BigDays.sfdfT)
summary(modelFinalC)
hist(resid(modelFinalC))
range(exp(predict(modelFinalC)))
plot(log(BigDays.sfdfT$GroupDayCas), predict(modelFinalC))
cor(BigDays.sfdfT$GroupDayCas, exp(predict(modelFinalC)))
```

```{r}
(plotresid_cas <- ggplot(modelFinalC, aes(.resid)) + 
  geom_histogram(bins = 30, 
                 alpha = 0.9, 
                 color = "white", 
                 fill = "Grey40",
                 size = 0.1) +
   xlab("Residuals")  +
  ylab("Count") + 
 # ggtitle("B") +
  theme_bw() +
  theme(text = element_text(size=12), plot.background = element_rect(color = "grey40"), panel.border = element_rect(color = "white"), plot.margin=unit(c(0.5, 0.5, 0.5, 0.5),"cm")))
```

```{r}
predscas <- predict(modelFinalC)
BigDays.sfdfT = cbind(BigDays.sfdfT, predscas)

cc <- scales::seq_gradient_pal("skyblue", "blue")(seq(0,1,length.out=12))

ggplot(BigDays.sfdfT, aes(x = log(GroupDayCas), y = predscas)) +
  geom_point(size = 4,  show.legend = FALSE, stroke = 0, alpha = 0.8, color = "Grey40") +
      #scale_color_continuous()
      scale_color_manual(values = cc) +
      #scale_colour_gradient(low = "Grey", high = "Grey70") +
      geom_abline(slope = 1, size = 1.25) + 
      ylab("Estimated Casualties") + xlab("Actual Casualties") +
      scale_x_log10() +
      scale_y_log10() +
      theme_minimal() + theme(text = element_text(size=10), plot.background = element_rect(colour = 'grey40'))#, panel.border = element_rect(color = "Grey40")) 

ggplot(BigDays.sfdfT, aes(x = GroupDayCas, y = exp(predscas-1))) +
  geom_point(size = 4,  show.legend = FALSE, stroke = 0, alpha = 0.8, color = "Grey40") +
      #scale_color_continuous()
      scale_color_manual(values = cc) +
      #scale_colour_gradient(low = "Grey", high = "Grey70") +
      geom_abline() + 
      ylab("Estimated Casualties") + 
      xlab("Actual Casualties") +
      scale_x_log10(breaks = c(0,1,  10, 50, 500, 1500, 3000), labels = c("0", "1", "10","50", "500", "1500", "3000")) +
      scale_y_log10(breaks = c(0, 1, 10, 50, 500, 1500, 3000), labels = c("0","1", "10", "50", "500", "1500", "3000")) +
      theme_minimal() + 
        theme(text = element_text(size=10), plot.background = element_rect(colour = 'grey40'))
```

Fig 2: Not so elongated. Square panels. Num clus, num torn; 



Use this as prospectus. THis is what you plan to do in the next 8 months. Write it up and defend dissertation. Look at how you wrote for Dr. Horners. 
